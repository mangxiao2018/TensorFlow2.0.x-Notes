{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "1.18.4\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "# 忽略掉警告信息，使用界面更清爽\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在终端执行程序时指定GPU  \n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1   python  your_file.py\n",
    "\n",
    "# 这样在跑你的网络之前，告诉程序只能看到1号GPU，其他的GPU它不可见\n",
    "\n",
    "# 可用的形式如下：\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1           Only device 1 will be seen\n",
    "# CUDA_VISIBLE_DEVICES=0,1         Devices 0 and 1 will be visible\n",
    "# CUDA_VISIBLE_DEVICES=\"0,1\"       Same as above, quotation marks are optional\n",
    "# CUDA_VISIBLE_DEVICES=0,2,3       Devices 0, 2, 3 will be visible; device 1 is masked\n",
    "# CUDA_VISIBLE_DEVICES=\"\"          No GPU will be visible\n",
    "\n",
    "\n",
    "\n",
    "# 在Python代码中指定GPU\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "# 设置定量的GPU使用量\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 占用GPU90%的显存\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "\n",
    "\n",
    "# 设置最小的GPU使用量\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定CUDA设备\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.test.is_gpu_available() # 高版本已废弃不再使用\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "# cpus = tf.config.list_physical_devices(device_type='CPU')\n",
    "# print(gpus, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "# print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "# CPU\n",
    "# cpus = tf.config.experimental.list_physical_devices(device_type='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练数据，测试数据\n",
    "mnist = np.load(\"mnist.npz\")\n",
    "x_train, y_train, x_test, y_test = mnist['x_train'],mnist['y_train'],mnist['x_test'],mnist['y_test']\n",
    "# 归一化\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加通道维度\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# x_train\n",
    "# x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset.from_tensor_slices\n",
    "# 该函数是dataset核心函数之一，它的作用是把给定的元组、列表和张量等数据进行特征切片。切片的范围是从最外层维度开始的。\n",
    "# 如果有多个特征进行组合，那么一次切片是把每个组合的最外维度的数据切开，分成一组一组的。\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation = 'relu')\n",
    "        self.d2 = Dense(10, activation='softmax')\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "# @tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "import os\n",
    "logdir = os.path.join('keras_logv4')\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (x_train, y_train) in train_ds:\n",
    "        train_step(x_train, y_train)\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "with summary_writer.as_default():\n",
    "    tf.summary.trace_on(graph=True, profiler=False)\n",
    "    tf.summary.trace_export(name=\"model_trace\", step=3, profiler_outdir=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./keras_logv4/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.create_file_writer('./tensorboard')\n",
    "log_dir = \"graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.03226933255791664, Accuracy: 98.98333740234375, TestLoss : 0.048861049115657806, Test Accuracy: 98.44999694824219\n",
      "Epoch 2, Loss: 0.013172667473554611, Accuracy: 99.56500244140625, TestLoss : 0.06103254109621048, Test Accuracy: 98.29999542236328\n",
      "Epoch 3, Loss: 0.009416600689291954, Accuracy: 99.67832946777344, TestLoss : 0.05992802977561951, Test Accuracy: 98.40999603271484\n",
      "Epoch 4, Loss: 0.00683900760486722, Accuracy: 99.77166748046875, TestLoss : 0.06621938198804855, Test Accuracy: 98.32999420166016\n",
      "Epoch 5, Loss: 0.006631186231970787, Accuracy: 99.75833129882812, TestLoss : 0.062243957072496414, Test Accuracy: 98.47999572753906\n"
     ]
    }
   ],
   "source": [
    "summary_writer = tf.summary.create_file_writer('./tensorboard')\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer('./tensorboard')\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (x_train, y_train) in train_ds:\n",
    "        train_step(x_train, y_train)\n",
    "        \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "    \n",
    "    for(x_test, y_test) in test_ds:\n",
    "        test_step(x_test, y_test)\n",
    "        \n",
    "    tf.summary.trace_on(graph=True, profiler=True)\n",
    "    \n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=log_dir)\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, TestLoss : {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result() * 100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result() * 100))\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
