{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 版本模型保存与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型与加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x_train = np.random.random((1000, 32))\n",
    "y_train = np.random.randint(10,size=(1000,))\n",
    "x_val = np.random.random((200,32))\n",
    "y_val = np.random.randint(10,size=(200,))\n",
    "x_test = np.random.random((200,32))\n",
    "y_test = np.random.randint(10,size=(200,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = tf.keras.Input(shape=(32,), name='digits')\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "    outputs = tf.keras.layers.Dense(10, name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs=inputs,outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 627us/sample - loss: 2.3216 - sparse_categorical_accuracy: 0.1080 - val_loss: 2.3229 - val_sparse_categorical_accuracy: 0.0950\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 2.2932 - sparse_categorical_accuracy: 0.1120 - val_loss: 2.3215 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 2.2802 - sparse_categorical_accuracy: 0.1260 - val_loss: 2.3218 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 2.2718 - sparse_categorical_accuracy: 0.1460 - val_loss: 2.3127 - val_sparse_categorical_accuracy: 0.1050\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 2.2601 - sparse_categorical_accuracy: 0.1540 - val_loss: 2.3175 - val_sparse_categorical_accuracy: 0.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e4f04c9688>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3473292 ,  0.3046521 , -0.23478134, ...,  0.13323289,\n",
       "        -0.34092686, -0.01059906],\n",
       "       [ 0.16159756,  0.01305328,  0.08097283, ..., -0.01362841,\n",
       "         0.1453599 , -0.02191441],\n",
       "       [ 0.33781755,  0.25096965, -0.19106542, ...,  0.3070628 ,\n",
       "        -0.1019905 , -0.07908364],\n",
       "       ...,\n",
       "       [ 0.04942468,  0.14382668, -0.2340227 , ...,  0.11744707,\n",
       "        -0.12604512,  0.16752988],\n",
       "       [ 0.01535964,  0.06849495, -0.08979256, ..., -0.20046854,\n",
       "         0.03855814,  0.08254822],\n",
       "       [ 0.08698934,  0.11025517, -0.0973656 , ..., -0.03306213,\n",
       "         0.25290254,  0.3312022 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('adasd.h5')\n",
    "model.load_weights('adasd.h5')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3473292 ,  0.3046521 , -0.23478134, ...,  0.13323289,\n",
       "        -0.34092686, -0.01059906],\n",
       "       [ 0.16159756,  0.01305328,  0.08097283, ..., -0.01362841,\n",
       "         0.1453599 , -0.02191441],\n",
       "       [ 0.33781755,  0.25096965, -0.19106542, ...,  0.3070628 ,\n",
       "        -0.1019905 , -0.07908364],\n",
       "       ...,\n",
       "       [ 0.04942468,  0.14382668, -0.2340227 , ...,  0.11744707,\n",
       "        -0.12604512,  0.16752988],\n",
       "       [ 0.01535964,  0.06849495, -0.08979256, ..., -0.20046854,\n",
       "         0.03855814,  0.08254822],\n",
       "       [ 0.08698934,  0.11025517, -0.0973656 , ..., -0.03306213,\n",
       "         0.25290254,  0.3312022 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\zhangyanqing\\.conda\\envs\\tf2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: keras_model_tf_version\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.3473292 ,  0.3046521 , -0.23478134, ...,  0.13323289,\n",
       "        -0.34092686, -0.01059906],\n",
       "       [ 0.16159756,  0.01305328,  0.08097283, ..., -0.01362841,\n",
       "         0.1453599 , -0.02191441],\n",
       "       [ 0.33781755,  0.25096965, -0.19106542, ...,  0.3070628 ,\n",
       "        -0.1019905 , -0.07908364],\n",
       "       ...,\n",
       "       [ 0.04942468,  0.14382668, -0.2340227 , ...,  0.11744707,\n",
       "        -0.12604512,  0.16752988],\n",
       "       [ 0.01535964,  0.06849495, -0.08979256, ..., -0.20046854,\n",
       "         0.03855814,  0.08254822],\n",
       "       [ 0.08698934,  0.11025517, -0.0973656 , ..., -0.03306213,\n",
       "         0.25290254,  0.3312022 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the model to a SavedModel\n",
    "model.save('keras_model_tf_version', save_format='tf')\n",
    "\n",
    "#Recreate the exact same model\n",
    "new_model = tf.keras.models.load_model('keras_model_tf_version')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3473292 ,  0.3046521 , -0.23478134, ...,  0.13323289,\n",
       "        -0.34092686, -0.01059906],\n",
       "       [ 0.16159756,  0.01305328,  0.08097283, ..., -0.01362841,\n",
       "         0.1453599 , -0.02191441],\n",
       "       [ 0.33781755,  0.25096965, -0.19106542, ...,  0.3070628 ,\n",
       "        -0.1019905 , -0.07908364],\n",
       "       ...,\n",
       "       [ 0.04942468,  0.14382668, -0.2340227 , ...,  0.11744707,\n",
       "        -0.12604512,  0.16752988],\n",
       "       [ 0.01535964,  0.06849495, -0.08979256, ..., -0.20046854,\n",
       "         0.03855814,  0.08254822],\n",
       "       [ 0.08698934,  0.11025517, -0.0973656 , ..., -0.03306213,\n",
       "         0.25290254,  0.3312022 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('keras_model_hdf5_version.h5')\n",
    "\n",
    "new_model = tf.keras.models.load_model('keras_model_hdf5_version.h5')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法四 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_saved_model_version\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'tf_saved_model_version')\n",
    "restored_saved_model = tf.saved_model.load('tf_saved_model_version')\n",
    "f = restored_saved_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': <tf.Tensor: id=6595, shape=(200, 10), dtype=float32, numpy=\n",
       " array([[ 0.3473292 ,  0.3046521 , -0.23478134, ...,  0.13323289,\n",
       "         -0.34092686, -0.01059906],\n",
       "        [ 0.16159756,  0.01305328,  0.08097283, ..., -0.01362841,\n",
       "          0.1453599 , -0.02191441],\n",
       "        [ 0.33781755,  0.25096965, -0.19106542, ...,  0.3070628 ,\n",
       "         -0.1019905 , -0.07908364],\n",
       "        ...,\n",
       "        [ 0.04942468,  0.14382668, -0.2340227 , ...,  0.11744707,\n",
       "         -0.12604512,  0.16752988],\n",
       "        [ 0.01535964,  0.06849495, -0.08979256, ..., -0.20046854,\n",
       "          0.03855814,  0.08254822],\n",
       "        [ 0.08698934,  0.11025517, -0.0973656 , ..., -0.03306213,\n",
       "          0.25290254,  0.3312022 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['digits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 32)\n",
      "        name: serving_default_digits:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predictions'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-02 15:00:05.745386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir tf_saved_model_version --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义版本模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        #自定义需要的层\n",
    "        self.dense_1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(num_classes)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,32], tf.float32, name='digits')])\n",
    "    def call(self, inputs):\n",
    "        # 定义前向传播\n",
    "        # 使用__init__定义的层\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.random.random((1000,32))\n",
    "y_train = np.random.random((1000,10))\n",
    "x_val = np.random.random((200,32))\n",
    "y_val = np.random.random((200,10))\n",
    "x_test = np.random.random((200, 32))\n",
    "y_test = np.random.random((200, 10))\n",
    "\n",
    "# 优化器\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# 损失函数\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 准备metrics函数\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# 准备训练数据集\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# 准备测试数据集\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "val_dataset = val_dataset.batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Training loss (for on batch) at step 0: 11.79886531829834\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch : 0.10599999874830246\n",
      "Validation acc: 0.10499999672174454\n",
      "Start of epoch 1\n",
      "Training loss (for on batch) at step 0: 11.923458099365234\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch : 0.10400000214576721\n",
      "Validation acc: 0.0949999988079071\n",
      "Start of epoch 2\n",
      "Training loss (for on batch) at step 0: 11.96838665008545\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch : 0.10000000149011612\n",
      "Validation acc: 0.10499999672174454\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(num_classes = 10)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    \n",
    "    #遍历数据集的batch_size\n",
    "    for step, (x_batch_train,y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value,model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
    "        \n",
    "        # 更新训练集metrics\n",
    "        train_acc_metric(y_batch_train,logits)\n",
    "        # 每200 batches 打印一次\n",
    "        if step % 200 == 0:\n",
    "            print('Training loss (for on batch) at step %s: %s' % (step,float(loss_value)))\n",
    "            print('Seen so far: %s samples' % ((step + 1) * 64))\n",
    "        \n",
    "    # 每200 batches 打印一次\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print('Training acc over epoch : %s' % (float(train_acc),))\n",
    "    # 在每个epoch结束时重置训练指标\n",
    "    train_acc_metric.reset_states()\n",
    "        \n",
    "    # 在每个epoch结束时运行一个验证集\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val)\n",
    "        # 更新验证集metrics\n",
    "        val_acc_metric(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print('Validation acc: %s' % (float(val_acc),))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4654854 , -0.01458457,  0.15748456, ...,  0.3054785 ,\n",
       "         0.57802564,  0.38118216],\n",
       "       [ 0.03840728, -0.19577438,  0.10128754, ...,  0.09494125,\n",
       "         0.6286599 ,  0.19895615],\n",
       "       [-0.07822809,  0.39466432,  0.18232784, ...,  0.5844623 ,\n",
       "         0.3728618 ,  0.7531386 ],\n",
       "       ...,\n",
       "       [ 0.8180418 , -0.5025957 , -0.32610843, ...,  0.2350072 ,\n",
       "         0.91166764,  0.7778447 ],\n",
       "       [ 0.36247116, -0.3068242 , -0.13966909, ...,  0.192061  ,\n",
       "         0.50103104,  0.1897213 ],\n",
       "       [ 0.03541934, -0.07327286, -0.28988874, ...,  0.25282496,\n",
       "         0.24358226,  0.28250873]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"adasd.h5\")\n",
    "model.load_weights(\"adasd.h5\")\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4654854 , -0.01458457,  0.15748456, ...,  0.3054785 ,\n",
       "         0.57802564,  0.38118216],\n",
       "       [ 0.03840728, -0.19577438,  0.10128754, ...,  0.09494125,\n",
       "         0.6286599 ,  0.19895615],\n",
       "       [-0.07822809,  0.39466432,  0.18232784, ...,  0.5844623 ,\n",
       "         0.3728618 ,  0.7531386 ],\n",
       "       ...,\n",
       "       [ 0.8180418 , -0.5025957 , -0.32610843, ...,  0.2350072 ,\n",
       "         0.91166764,  0.7778447 ],\n",
       "       [ 0.36247116, -0.3068242 , -0.13966909, ...,  0.192061  ,\n",
       "         0.50103104,  0.1897213 ],\n",
       "       [ 0.03541934, -0.07327286, -0.28988874, ...,  0.25282496,\n",
       "         0.24358226,  0.28250873]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存方法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26871058,  0.13238555, -0.02399828, ...,  0.09735883,\n",
       "         0.24049371, -0.11521427],\n",
       "       [ 0.04897687,  0.12739743,  0.01778143, ...,  0.23483427,\n",
       "        -0.07434058,  0.07764767],\n",
       "       [-0.18919535, -0.08100177,  0.12509204, ...,  0.02420731,\n",
       "         0.16034783, -0.03157626],\n",
       "       ...,\n",
       "       [ 0.06580651,  0.14493288, -0.0389459 , ...,  0.03956239,\n",
       "         0.22903194,  0.08431342],\n",
       "       [ 0.17668797,  0.17996134, -0.12930757, ...,  0.09321087,\n",
       "         0.00757388, -0.03637813],\n",
       "       [-0.09938693, -0.13643418, -0.13194056, ..., -0.0158865 ,\n",
       "        -0.2620629 ,  0.1127703 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save('my_saved_model.h5')\n",
    "# new_model = tf.keras.models.load_model('my_saved_model')\n",
    "# new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存方法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('path_to_my_model',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('path_to_my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4654854 , -0.01458457,  0.15748456, ...,  0.3054785 ,\n",
       "         0.57802564,  0.38118216],\n",
       "       [ 0.03840728, -0.19577438,  0.10128754, ...,  0.09494125,\n",
       "         0.6286599 ,  0.19895615],\n",
       "       [-0.07822809,  0.39466432,  0.18232784, ...,  0.5844623 ,\n",
       "         0.3728618 ,  0.7531386 ],\n",
       "       ...,\n",
       "       [ 0.8180418 , -0.5025957 , -0.32610843, ...,  0.2350072 ,\n",
       "         0.91166764,  0.7778447 ],\n",
       "       [ 0.36247116, -0.3068242 , -0.13966909, ...,  0.192061  ,\n",
       "         0.50103104,  0.1897213 ],\n",
       "       [ 0.03541934, -0.07327286, -0.28988874, ...,  0.25282496,\n",
       "         0.24358226,  0.28250873]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存方法四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'my_saved_model')\n",
    "restored_saved_model = tf.saved_model.load('my_saved_model')\n",
    "f = restored_saved_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: id=31416, shape=(200, 10), dtype=float32, numpy=\n",
       " array([[ 0.4654854 , -0.01458457,  0.15748456, ...,  0.3054785 ,\n",
       "          0.57802564,  0.38118216],\n",
       "        [ 0.03840728, -0.19577438,  0.10128754, ...,  0.09494125,\n",
       "          0.6286599 ,  0.19895615],\n",
       "        [-0.07822809,  0.39466432,  0.18232784, ...,  0.5844623 ,\n",
       "          0.3728618 ,  0.7531386 ],\n",
       "        ...,\n",
       "        [ 0.8180418 , -0.5025957 , -0.32610843, ...,  0.2350072 ,\n",
       "          0.91166764,  0.7778447 ],\n",
       "        [ 0.36247116, -0.3068242 , -0.13966909, ...,  0.192061  ,\n",
       "          0.50103104,  0.1897213 ],\n",
       "        [ 0.03541934, -0.07327286, -0.28988874, ...,  0.25282496,\n",
       "          0.24358226,  0.28250873]], dtype=float32)>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-02 17:12:23.111325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['digits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 32)\n",
      "        name: serving_default_digits:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir my_saved_model --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_test.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = list(map(lambda x : int(x),a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(digits = tf.constant([aa]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
